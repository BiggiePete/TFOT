{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee3484f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow==2.18.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.18.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.18.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.14.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (25.2.10)\n",
      "Collecting numpy<2.1.0,>=1.26.0\n",
      "  Downloading numpy-2.0.2-cp310-cp310-win_amd64.whl (15.9 MB)\n",
      "     --------------------------------------- 15.9/15.9 MB 32.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.31.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.4.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.17.2)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (1.74.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.3.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.18.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (5.29.5)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (4.14.1)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (18.1.1)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.6.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (23.2)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.2.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.31.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (63.2.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.4.1)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.1.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.10.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.45.1)\n",
      "Requirement already satisfied: namex in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.1.0)\n",
      "Requirement already satisfied: optree in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.17.0)\n",
      "Requirement already satisfied: rich in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (14.1.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2024.2.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.8.2)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.0.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\dingus\\appdata\\roaming\\python\\python310\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow==2.18.0) (0.1.2)\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.22.0\n",
      "    Uninstalling numpy-1.22.0:\n",
      "      Successfully uninstalled numpy-1.22.0\n",
      "Successfully installed numpy-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "accelerate 0.25.0 requires torch>=1.10.0, which is not installed.\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -orch (c:\\users\\dingus\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip available: 22.2.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "#@title ### **2. Setup Environment & TTS Model**\n",
    "#@markdown This cell will install all required packages, including the powerful `TTS` library **and its system dependency `espeak-ng`**. It will then download and load the specified TTS model.\n",
    "#@markdown <br>\n",
    "#@markdown *This may take seemingly forever, especially the first time.*\n",
    "#@markdown *If this is the first time, you will likely need to \"restart\" the runtime*\n",
    "# 1. Install Python packages\n",
    "# !pip uninstall -y keras tensorflow\n",
    "%pip install tensorflow==2.18.0\n",
    "\n",
    "%pip install TTS==0.22.0 tensorflow-model-optimization pydub librosa soundfile tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab745c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title <h1>Advanced Speech Dataset Generator (Local TTS)</h1>\n",
    "#@markdown This notebook uses a powerful, local, open-source Text-to-Speech (TTS) model to generate the dataset. This completely avoids API rate limits and produces much more human-sounding speech.\n",
    "#@markdown <br>\n",
    "#@markdown **Key Improvements:**\n",
    "#@markdown - **No API Errors:** All generation is done locally on the Colab CPU/GPU.\n",
    "#@markdown - **High-Quality Voice:** Uses a state-of-the-art model (VITS) for natural, human-like speech.\n",
    "#@markdown - **Fast Generation:** Leverages the GPU if available for a significant speed-up.\n",
    "#@markdown - **Robust Pipeline:** Retains all previous features like background noise mixing and data augmentation.\n",
    "\n",
    "#@markdown ---\n",
    "#@markdown ### **1. Configuration**\n",
    "#@markdown Set your desired parameters. The TTS model will be downloaded automatically.\n",
    "\n",
    "words_to_generate = \"talking, fish\" #@param {type:\"string\"}\n",
    "samples_per_word = 1000 #@param {type:\"integer\"}\n",
    "output_directory_name = \"speech_commands_dataset_local\" #@param {type:\"string\"}\n",
    "# You can find more models here: https://huggingface.co/coqui/vits-v2-ljspeech-en\n",
    "tts_model_name = \"tts_models/en/ljspeech/vits\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "# --- End of Configuration ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd914f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Build Sound samples\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "from TTS.api import TTS\n",
    "from pydub import AudioSegment\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import requests\n",
    "\n",
    "\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "\n",
    "# Get device and load the TTS model\n",
    "# This will now work because espeak-ng is visible after the restart\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Loading TTS model: {tts_model_name}...\")\n",
    "synthesizer = TTS(tts_model_name).to(device)\n",
    "print(\"✅ TTS model loaded successfully.\")\n",
    "\n",
    "# --- The Generator Class ---\n",
    "class SpeechDatasetGenerator:\n",
    "    def __init__(self, words, samples_per_word, synthesizer, output_dir=\"speech_commands_dataset\"):\n",
    "        self.words = [word.strip() for word in words.split(',')]\n",
    "        self.samples_per_word = samples_per_word\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.synthesizer = synthesizer\n",
    "        # Standardize on 16kHz for speech commands, which is the most common for these tasks.\n",
    "        self.target_sample_rate = 16000\n",
    "        self.duration_ms = 1000\n",
    "\n",
    "        self.setup_directories()\n",
    "\n",
    "    def setup_directories(self):\n",
    "        if self.output_dir.exists():\n",
    "            shutil.rmtree(self.output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        for word in self.words:\n",
    "            (self.output_dir / word).mkdir(exist_ok=True)\n",
    "        self.noise_dir = self.output_dir / \"_background_noise_\"\n",
    "        self.noise_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    def generate_tts_samples(self, word):\n",
    "        print(f\"Generating {self.samples_per_word} samples for word: '{word}'\")\n",
    "        word_path = self.output_dir / word\n",
    "        pbar = tqdm(total=self.samples_per_word, desc=f\"Generating '{word}'\")\n",
    "        for i in range(self.samples_per_word):\n",
    "            try:\n",
    "                temp_file = Path(f\"temp_{word}.wav\")\n",
    "                self.synthesizer.tts_to_file(text=word, file_path=str(temp_file))\n",
    "\n",
    "                audio = AudioSegment.from_wav(temp_file)\n",
    "                # Resample to the target rate and ensure mono\n",
    "                audio = audio.set_frame_rate(self.target_sample_rate).set_channels(1)\n",
    "                audio = self.apply_audio_effects(audio)\n",
    "\n",
    "                if len(audio) > self.duration_ms:\n",
    "                    start_trim = (len(audio) - self.duration_ms) // 2\n",
    "                    audio = audio[start_trim:start_trim + self.duration_ms]\n",
    "                elif len(audio) < self.duration_ms:\n",
    "                    # Calculate the amount of silence needed\n",
    "                    padding_ms = self.duration_ms - len(audio)\n",
    "                    # Create a silent audio segment\n",
    "                    silence_segment = AudioSegment.silent(duration=padding_ms)\n",
    "                    # Add the silence to the end of the original audio\n",
    "                    audio = audio + silence_segment\n",
    "\n",
    "                audio = self.mix_with_background_noise(audio)\n",
    "                audio = audio.normalize()\n",
    "                output_file = word_path / f\"{word}_{i:04d}.wav\"\n",
    "                audio.export(output_file, format=\"wav\")\n",
    "                temp_file.unlink()\n",
    "                pbar.update(1)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"\\nError generating sample {i} for '{word}': {e}. Skipping.\")\n",
    "                if 'temp_file' in locals() and temp_file.exists():\n",
    "                    temp_file.unlink()\n",
    "                continue\n",
    "        pbar.close()\n",
    "\n",
    "    def apply_audio_effects(self, audio):\n",
    "        audio += random.uniform(-6, 2)\n",
    "        samples = np.array(audio.get_array_of_samples()).astype(np.float32)\n",
    "        if random.random() < 0.6:\n",
    "            n_steps = random.uniform(-1.5, 1.5)\n",
    "            samples = librosa.effects.pitch_shift(y=samples, sr=audio.frame_rate, n_steps=n_steps)\n",
    "        return AudioSegment(samples.astype(np.int16).tobytes(), frame_rate=audio.frame_rate, sample_width=2, channels=1)\n",
    "\n",
    "    def download_background_noise(self):\n",
    "        print(\"Downloading official background noise files...\")\n",
    "        url = \"http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\"\n",
    "        archive_path = self.output_dir / \"speech_commands.tar.gz\"\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(archive_path, 'wb') as f:\n",
    "                for chunk in tqdm(r.iter_content(chunk_size=8192), desc=\"Downloading archive\"):\n",
    "                    f.write(chunk)\n",
    "        shutil.unpack_archive(archive_path, self.output_dir)\n",
    "        archive_path.unlink()\n",
    "        for item in self.output_dir.iterdir():\n",
    "            if item.is_dir() and item.name != \"_background_noise_\" and item.name not in self.words:\n",
    "                shutil.rmtree(item)\n",
    "            elif item.is_file() and not item.name.endswith(('.md', '.txt')):\n",
    "                item.unlink()\n",
    "        self.background_noises = [AudioSegment.from_wav(f) for f in self.noise_dir.glob(\"*.wav\")]\n",
    "        print(f\"✓ Loaded {len(self.background_noises)} background noise files.\")\n",
    "\n",
    "    def mix_with_background_noise(self, audio):\n",
    "        if not hasattr(self, 'background_noises') or not self.background_noises or random.random() < 0.1:\n",
    "            return audio\n",
    "        noise = random.choice(self.background_noises)\n",
    "        if len(noise) > self.duration_ms:\n",
    "            start_pos = random.randint(0, len(noise) - self.duration_ms)\n",
    "            noise_snippet = noise[start_pos:start_pos + self.duration_ms]\n",
    "        else:\n",
    "            noise_snippet = noise\n",
    "        snr_db = random.uniform(5, 20)\n",
    "        return audio.overlay(noise_snippet, gain_during_overlay=-snr_db)\n",
    "\n",
    "    def create_split_lists(self):\n",
    "        all_files = [f\"{w}/{f.name}\" for w in self.words for f in (self.output_dir / w).glob('*.wav')]\n",
    "        random.shuffle(all_files)\n",
    "        val_idx = int(0.8 * len(all_files))\n",
    "        test_idx = int(0.9 * len(all_files))\n",
    "        (self.output_dir / \"validation_list.txt\").write_text('\\n'.join(all_files[val_idx:test_idx]))\n",
    "        (self.output_dir / \"testing_list.txt\").write_text('\\n'.join(all_files[test_idx:]))\n",
    "\n",
    "    def generate_dataset(self):\n",
    "        print(\"=\"*50)\n",
    "        print(\"Starting Local TTS Dataset Generation Pipeline\")\n",
    "        print(\"=\"*50)\n",
    "        self.download_background_noise()\n",
    "        for word in self.words:\n",
    "            self.generate_tts_samples(word)\n",
    "        self.create_split_lists()\n",
    "        print(\"\\nCreating zip file...\")\n",
    "        shutil.make_archive(self.output_dir.name, 'zip', self.output_dir)\n",
    "        print(\"🎉 DATASET GENERATION COMPLETE! 🎉\")\n",
    "\n",
    "# --- Verification Functions (Corrected) ---\n",
    "def load_dataset_for_tensorflow(dataset_path: Path):\n",
    "    if not dataset_path.exists():\n",
    "        print(f\"Error: Dataset path '{dataset_path}' does not exist.\")\n",
    "        return None\n",
    "    def get_label(file_path_tensor):\n",
    "        parts = tf.strings.split(file_path_tensor, os.path.sep)\n",
    "        return parts[-2]\n",
    "    def decode_audio(audio_binary):\n",
    "        audio, _ = tf.audio.decode_wav(audio_binary, desired_channels=1)\n",
    "        return tf.squeeze(audio, axis=-1)\n",
    "    def get_waveform_and_label(file_path_tensor):\n",
    "        label = get_label(file_path_tensor)\n",
    "        audio_binary = tf.io.read_file(file_path_tensor)\n",
    "        waveform = decode_audio(audio_binary)\n",
    "        return waveform, label\n",
    "\n",
    "    all_files_pattern = str(dataset_path / '*/*.wav')\n",
    "    filenames = tf.io.gfile.glob(all_files_pattern)\n",
    "    command_filenames = [f for f in filenames if '_background_noise_' not in f]\n",
    "\n",
    "    if not command_filenames:\n",
    "        print(\"Error: No command audio files found. Check the directory structure.\")\n",
    "        return None\n",
    "\n",
    "    files_ds = tf.data.Dataset.from_tensor_slices(command_filenames)\n",
    "    waveform_ds = files_ds.map(get_waveform_and_label, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    return waveform_ds\n",
    "\n",
    "def verify_dataset(dataset_path_str: str):\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Verifying generated dataset...\")\n",
    "    print(\"=\"*50)\n",
    "    dataset_path = Path(dataset_path_str)\n",
    "    if not dataset_path.exists():\n",
    "      print(f\"✗ Verification failed: Directory '{dataset_path}' not found.\")\n",
    "      return\n",
    "\n",
    "    command_dirs = [p for p in dataset_path.iterdir() if p.is_dir() and not p.name.startswith('_')]\n",
    "    for word_dir in command_dirs:\n",
    "        file_count = len(list(word_dir.glob('*.wav')))\n",
    "        print(f\"✓ Word '{word_dir.name}': Found {file_count} audio files.\")\n",
    "\n",
    "    try:\n",
    "        ds = load_dataset_for_tensorflow(dataset_path)\n",
    "        if ds is None: raise ValueError(\"Dataset could not be loaded.\")\n",
    "        print(\"\\n--- TensorFlow Compatibility Check ---\")\n",
    "        for waveform, label in ds.take(3):\n",
    "            print(f\"Sample - Label: {label.numpy().decode('utf-8'):<10} \"\n",
    "                  f\"Shape: {waveform.shape}, \"\n",
    "                  f\"Duration: {waveform.shape[0] / 16000:.2f}s\")\n",
    "        print(\"\\n✅ Dataset verification successful.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n✗ Error during dataset verification: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2683f4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate the dataset\n",
    "generator = SpeechDatasetGenerator(\n",
    "    words=words_to_generate,\n",
    "    samples_per_word=samples_per_word,\n",
    "    synthesizer=synthesizer,\n",
    "    output_dir=output_directory_name\n",
    ")\n",
    "generator.generate_dataset()\n",
    "\n",
    "# 2. Verify the generated dataset\n",
    "verify_dataset(output_directory_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
